{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Hebert Summarizer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d7a7740e31ad4020af10aa43b072a7e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_144474de74de42be882bb93264582444","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b77fa5ea6ac04cada02eb5f398f3cc98","IPY_MODEL_dd68c505de064fac9e904bc4c045b5ff","IPY_MODEL_c8ecf435658a4c348967e4c327ce8376"]}},"144474de74de42be882bb93264582444":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b77fa5ea6ac04cada02eb5f398f3cc98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1b554e339274c4da80b0e9530814702","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b7441ea47974be0a91cd506c9ae8782"}},"dd68c505de064fac9e904bc4c045b5ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b3d12ba25bd54aa7a96ff77e087924ca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":505,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":505,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0923e85ce52f48a592f643fc01d805e6"}},"c8ecf435658a4c348967e4c327ce8376":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da9fa74beb2143b094200324ae62ff5a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 505/505 [00:00&lt;00:00, 8.29kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5705f612c5b944d29cc8681b121a8686"}},"a1b554e339274c4da80b0e9530814702":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3b7441ea47974be0a91cd506c9ae8782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3d12ba25bd54aa7a96ff77e087924ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0923e85ce52f48a592f643fc01d805e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da9fa74beb2143b094200324ae62ff5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5705f612c5b944d29cc8681b121a8686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8a718be92bd4978a0b313b53edfc1dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_08d39ccf92c144058fe72e7959f04678","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b342ef156d824ad890fb983c29c24c5a","IPY_MODEL_385dbf74e8804c678fbfcbc5d659bb54","IPY_MODEL_d544910f0fe9483589cc98220d62e7ea"]}},"08d39ccf92c144058fe72e7959f04678":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b342ef156d824ad890fb983c29c24c5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41b3dba8542f48638911ed6ab7b4b5f9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a69fe45825a846458690ff1855b4699c"}},"385dbf74e8804c678fbfcbc5d659bb54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_14d044912f134021b86bdef7860c7f04","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":438146887,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":438146887,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2882577741774f3696ad6558b65e0fb1"}},"d544910f0fe9483589cc98220d62e7ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee21745729fc409f8e27a243aec9a7f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 438M/438M [00:15&lt;00:00, 26.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ca88dce2fcb34cd5b33ba6b11b40a24d"}},"41b3dba8542f48638911ed6ab7b4b5f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a69fe45825a846458690ff1855b4699c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14d044912f134021b86bdef7860c7f04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2882577741774f3696ad6558b65e0fb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee21745729fc409f8e27a243aec9a7f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ca88dce2fcb34cd5b33ba6b11b40a24d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4ce6ad6f97c43a084d61f8d117c5a5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3da34d5bcfce4fcc9547b2cc01a891a0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_344813fc2c324424a2b45cfe4c335fb5","IPY_MODEL_8bc91cde9504450dbe754cb98f9d0a12","IPY_MODEL_10252d8eafcb482a9c6abcdf7f199a66"]}},"3da34d5bcfce4fcc9547b2cc01a891a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"344813fc2c324424a2b45cfe4c335fb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_89aa45b8c5fb48d0ae85df8c3b5b9964","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2120584250e7424ca42d036de4202721"}},"8bc91cde9504450dbe754cb98f9d0a12":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6ae843a316cc429f924c734320207eba","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":299405,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":299405,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec2d2112da544c7fac62010ee18a5998"}},"10252d8eafcb482a9c6abcdf7f199a66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6af17c2e6aa741d397c21d29432ea01e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 299k/299k [00:00&lt;00:00, 1.03MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_604c8a8b95144d088c46e595654b8d35"}},"89aa45b8c5fb48d0ae85df8c3b5b9964":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2120584250e7424ca42d036de4202721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ae843a316cc429f924c734320207eba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec2d2112da544c7fac62010ee18a5998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6af17c2e6aa741d397c21d29432ea01e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"604c8a8b95144d088c46e595654b8d35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"TZjRGjE3cGJD"},"source":["# Drive Mount, Installations, Import"]},{"cell_type":"markdown","metadata":{"id":"F_3fEueNcSWs"},"source":["## Import Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qh9CHjsM8ywk","executionInfo":{"status":"ok","timestamp":1630943564543,"user_tz":-180,"elapsed":23386,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"f1a6e3e8-017f-4838-80d2-431c567da556"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"rQNQM68ElATf"},"source":["## Installations"]},{"cell_type":"markdown","metadata":{"id":"w0RaI2drk6q1"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-_z_ivAm7ZT","executionInfo":{"status":"ok","timestamp":1630943585630,"user_tz":-180,"elapsed":21090,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"d0a8614a-ffb4-4479-d732-894003a5088f"},"source":["!pip install transformers\n","!git clone https://github.com/chriskhanhtran/bert-extractive-summarization.git\n","!pip install boto3\n","!pip install rouge\n","%cd bert-extractive-summarization"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 35.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 39.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n","Cloning into 'bert-extractive-summarization'...\n","remote: Enumerating objects: 239, done.\u001b[K\n","remote: Total 239 (delta 0), reused 0 (delta 0), pack-reused 239\u001b[K\n","Receiving objects: 100% (239/239), 321.37 KiB | 2.95 MiB/s, done.\n","Resolving deltas: 100% (123/123), done.\n","Collecting boto3\n","  Downloading boto3-1.18.36-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 5.3 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 6.9 MB/s \n","\u001b[?25hCollecting botocore<1.22.0,>=1.21.36\n","  Downloading botocore-1.21.36-py3-none-any.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 22.7 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 41.7 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.36->boto3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.36->boto3) (1.15.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.36 botocore-1.21.36 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.6\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n","/content/bert-extractive-summarization\n"]}]},{"cell_type":"markdown","metadata":{"id":"8DFLwYMElDh5"},"source":["## Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yg__HjUCnEGS","executionInfo":{"status":"ok","timestamp":1630943595171,"user_tz":-180,"elapsed":9556,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"fa65df85-691e-4415-d52f-725fe1b910cc"},"source":["import torch\n","from torch import nn\n","from torch.optim import Adam\n","import numpy as np  \n","import pandas as pd\n","from sklearn.metrics import jaccard_score\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","nltk.download('punkt')\n","from ext_sum import test\n","import random\n","from models.encoder import ExtTransformerEncoder\n","from transformers import BertTokenizer, BertModel, AutoModel\n","from plotly.figure_factory import create_table\n","from sklearn.model_selection import train_test_split\n","from rouge import Rouge\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ac--t6hxm5Zj"},"source":["## Data EDA and category selection"]},{"cell_type":"markdown","metadata":{"id":"b_C7KlgnpKOu"},"source":["### Data Load"]},{"cell_type":"code","metadata":{"id":"2-VU-DTzm4n8","executionInfo":{"status":"ok","timestamp":1630943601752,"user_tz":-180,"elapsed":5546,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["df = pd.read_csv('/content/drive/MyDrive/Masters First Year/NLP/Final Proj/Data/Hebrew articles/hebrew_news.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97},"id":"qPLTb7GspWeL","executionInfo":{"status":"ok","timestamp":1630943601753,"user_tz":-180,"elapsed":53,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"60e31654-f379-404f-dd81-4e6da2d4e824"},"source":["df.head(1)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>articleBody</th>\n","      <th>description</th>\n","      <th>headline</th>\n","      <th>keywords</th>\n","      <th>title</th>\n","      <th>type</th>\n","      <th>category</th>\n","      <th>source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>זה היה באוויר כבר יותר מחודשיים. העצמאות שבה ב...</td>\n","      <td>העצמאות שבה ניהל שלמה רודב את דירקטוריון בזק ה...</td>\n","      <td>סרצ'לייט רצתה להוכיח שליטה והראתה לרודב את הדלת</td>\n","      <td>['בזק', 'רודב', \"סרצ'לייט\"]</td>\n","      <td>סרצ'לייט רצתה להוכיח שליטה והראתה לרודב את הדלת</td>\n","      <td>article</td>\n","      <td>שוק ההון</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         articleBody  ... source\n","0  זה היה באוויר כבר יותר מחודשיים. העצמאות שבה ב...  ...      1\n","\n","[1 rows x 8 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"qb1CeMJ8pO0f"},"source":["### Data Random Sample\n","We see from the sample that the text description provides a better summerization of the texts, while the title mostly acts as a click-bait. Therefore we will use the description as our gold-label."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2S6ePranuOP","executionInfo":{"status":"ok","timestamp":1630943601754,"user_tz":-180,"elapsed":49,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"74e125fe-7aa3-4431-d08c-8b8c14c762a3"},"source":["sample = df.sample(1, random_state=42)\n","print('Sample Title:', sample['title'].values)\n","print('Sample Description:', sample['description'].values)\n","print('Sample Text:' , list(sample['articleBody'].values))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Title: ['הערב זה מתחיל: קווי התחבורה הציבורית שפועלים בשבת בגוש דן']\n","Sample Description: ['עם כניסת השבת החלו לפעול 6 קווים בתל אביב-יפו, גבעתיים, רמת השרון וקריית אונו. בכל חצי שעה יעברו האוטובוסים במאות תחנות שמוקמו בנקודות מרכזיות בערים המשתתפות במיזם. רבים כבר החלו לעשות שימוש בשירות. מקווים שלא יבוטל כיצד נראית מפת הקווים? כל הפרטים']\n","Sample Text: ['מיזם התחבורה הציבורית בשבת בגוש דן החל את פעילותו הערב (שישי). במהלך סוף השבוע יצאו לדרכם לראשונה חמישה קווי אוטובוס שייסעו בערים מרכזיות באזור, בהן תל אביב-יפו, גבעתיים, רמת השרון וקריית אונו. האוטובוסים יעברו על פני מאות תחנות שמוקמו בנקודות מרכזיות בערים השונות, ויחלפו על פניהן בכל חצי שעה. הקווים שהחלו לפעול הערב יסיימו את נסיעתם ב-01:00 או 03:00 בלילה, וישובו לפעילות מחר החל מ-09:00 בבוקר ועד לצאת השבת. בשלב זה יינתן השירות בחינם, ובהמשך ייקבע המחיר וכיצד ייגבה.כבר בשעות המוקדמות שלאחר כניסת השבת נראו נוסעים העושים שימוש לראשונה בשירות. בתחנה ברחוב כצנלסון בגבעתיים נצפו כמה צעירים שהחליטו לנצל את האוטובוסים החדש ולהימנע מהוויכוח על הנהג התורן.  \"אני נוסע הערב בתוך גבעתיים \", סיפר ניב מסיקה, בן 27. \"אני הולך עם חבר שלי לפאב. השירות הזה נשמע נחמד והחלטתי לנסות. הייתי בטוח שזה יעלה כסף במסגרת \\'חופשי חודשי\\', קצת מוזר שזה בחינם. אני רק מפחד שעכשיו החרדים ימחו\".\\nעמרי קמחי, בן 26 מרמת גן, המתין לקו 705 בדרכו לנחלת בנימין בתל אביב. \"שמעתי על כך בפייסבוק, אני מאוד בעד, זה חשוב\", אמר. על התחנה נתלו שלטי מחאה נגד המהלך. \"זה מיותר\", אמר. \"אם יהיה לזה הרבה ביקוש אז ימשיכו עם זה. נראה לי שהאוטובוסים יהיו מלאים בהמשך\". אוריאל פליישמן, בן 33 נוסע גם הוא לתל אביב: \"אני מנצל את ההזדמנות סוף סוף שהשירות הזה קיים כדי לצאת לתל אביב\". \"ראיתי מלא כתבות על זה ואני חושבת שזה מדהים\", סיפרה מאיה בת ה-17, שנוסעת גם היא מגבעתיים לשוק הפשפשים ביפו. \"זה במקום שאני אשלם על מוניות. זה משהו בסיסי שצריך להיות כמו בכל מדינה אחרת. אני לא מאמינה בכפייה דתית, אני חושבת שימשיכו עם זה\".\\nמספרי הקווים שיפעלו באזור המרכז יהיו 705, 706, 707, 708, 709 ו-710. לפי המסלולים שפורסמו באפליקציה \"אוטובוס קרוב\", קו 705 יפעל בין גבעתיים לחולון, קווים 706 ו-707 יפעלו בין רמת השרון ליפו, קו 708 ינוע בין צפון תל אביב לחולון, 709 מרמת השרון למזרח תל אביב וקו 710 ינוע בין קריית אונו לצפון תל אביב.קו 705 יתחיל את נסיעתו בתחנת המאבק/עמישב בגבעתיים. הוא יעבור ברחובות ויצמן וכצנלסון, דרך יגאל אלון, מנחם בגין, ארלוזורוב, אבן גבירול, בן יהודה ויפת בתל אביב, ובחולון ייסע בשדרות ירושלים עד שיגיע לתחנה הסופית במסוף וולפסון.קו 706 יתחיל את נסיעתו במסוף קדמה ברמת השרון, ימשיך ברחובות שבטי ישראל, טרומפלדור ואוסישקין ויחלוף על פני צומת הכפר הירוק. בתל אביב ייסע ברחוב משה סנה, שדרות קק\"ל, קניון רמת אביב, סמינר הקיבוצים, רחוב יהודה המכבי וכיכר המדינה. הוא יחלוף דרך רחובות מרכזיים במרכז העיר עד שיגיע לתחנתו הסופית בנמל יפו.\\nקו 707 ייצא מתחנת סוקולוב/יבנה ברמת השרון, ימשיך דרך הכפר הירוק, יעבור דרך רחוב בני אפרים לשדרות רוקח, יעבור דרך תחנת הרכבת באוניברסיטת תל אביב וימשיך דרך מרכז תל אביב לדרומה ברחובות אלנבי, העליה, דרך שלמה - עד לנמל יפו.קו 708 יתחיל את מסלולו במסוף עתידים בצפון תל אביב. הוא יחלוף על פני איצטדיון הדר יוסף, תחנת הרכבת באוניברסיטת תל אביב, רחובות דיזנגוף, קינג ג\\'ורג\\', אלנבי ולוינסקי בתל אביב ויסיים את נסיעתו במסוף וולפסון שבפאתי חולון.\\nקו 709 ייצא מהסינמה סיטי ברמת השרון, יעבור לאורך שדרות לוי אשכול בתל אביב, ברחובות ש\"י עגנון, אבן גבירול ודיזנגוף בתל אביב, ויחלוף על פני תיאטרון הבימה. הוא ימשיך דרך רחוב החשמונאים לדרום העיר ויעבור ברחובות המסגר יצחק שדה. משם ימשיך דרך לה גוורדיה למשה דיין ודרך בר לב עד למסוף הטייסים במזרח העיר.קו 710 יתחיל את מסלולו באקספו תל אביב (גני התערוכה), ימשיך דרך תחנת הרכבת באוניברסיטת תל אביב, יעבור דרך הרחובות בן יהודה, בן גוריון, אבן גבירול ושאול המלך בתל אביב וימשיך לדרך השלום. משם ימשיך לדרך אלוף שדה - עד לקריית אונו. בעיר הוא יעבור בסמוך לקניון ויסיים את נסיעתו בתחנת דרך רפאל איתן/יצחק רבין.(עדכון ראשון: 13:25)']\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q1x1Sh0Kpt7j"},"source":["### Understand the categories in the DataSet\n","we would like to select a single category from this list, and train our model on it. This is done due to lack of resources, long training time and the hypothesis that focusing on a single category will yield better results."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"-huJuI7Npsb-","executionInfo":{"status":"ok","timestamp":1630943601754,"user_tz":-180,"elapsed":33,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"74734010-b296-482b-cd20-8fccb835f767"},"source":["cate_df = pd.DataFrame(pd.Series(df['category']).value_counts())\n","print('These are the top labeled categories in our dataset:')\n","cate_df.head(10)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["These are the top labeled categories in our dataset:\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>בארץ</th>\n","      <td>2578</td>\n","    </tr>\n","    <tr>\n","      <th>טכנולוגי</th>\n","      <td>1725</td>\n","    </tr>\n","    <tr>\n","      <th>שוק ההון</th>\n","      <td>1302</td>\n","    </tr>\n","    <tr>\n","      <th>ועידות</th>\n","      <td>940</td>\n","    </tr>\n","    <tr>\n","      <th>נדל\"ן</th>\n","      <td>584</td>\n","    </tr>\n","    <tr>\n","      <th>Health</th>\n","      <td>577</td>\n","    </tr>\n","    <tr>\n","      <th>עולם</th>\n","      <td>541</td>\n","    </tr>\n","    <tr>\n","      <th>PnaiPlus</th>\n","      <td>367</td>\n","    </tr>\n","    <tr>\n","      <th>Economy</th>\n","      <td>367</td>\n","    </tr>\n","    <tr>\n","      <th>פרסום ושיווק</th>\n","      <td>343</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              category\n","בארץ              2578\n","טכנולוגי          1725\n","שוק ההון          1302\n","ועידות             940\n","נדל\"ן              584\n","Health             577\n","עולם               541\n","PnaiPlus           367\n","Economy            367\n","פרסום ושיווק       343"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"FqagSyoYyANp"},"source":["### Select the real-estate category"]},{"cell_type":"code","metadata":{"id":"um3zcjtOwo5t","executionInfo":{"status":"ok","timestamp":1630943601755,"user_tz":-180,"elapsed":10,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["re_df = df[df[\"category\"] == 'נדל\"ן']\n","re_texts = re_df['articleBody']\n","re_labels = re_df['description']"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SdBEl7NmlhP1"},"source":["# Preprocess"]},{"cell_type":"markdown","metadata":{"id":"PfKjqpxFlkRR"},"source":["## Init Hebrt Model, inc. weights"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["d7a7740e31ad4020af10aa43b072a7e3","144474de74de42be882bb93264582444","b77fa5ea6ac04cada02eb5f398f3cc98","dd68c505de064fac9e904bc4c045b5ff","c8ecf435658a4c348967e4c327ce8376","a1b554e339274c4da80b0e9530814702","3b7441ea47974be0a91cd506c9ae8782","b3d12ba25bd54aa7a96ff77e087924ca","0923e85ce52f48a592f643fc01d805e6","da9fa74beb2143b094200324ae62ff5a","5705f612c5b944d29cc8681b121a8686","e8a718be92bd4978a0b313b53edfc1dc","08d39ccf92c144058fe72e7959f04678","b342ef156d824ad890fb983c29c24c5a","385dbf74e8804c678fbfcbc5d659bb54","d544910f0fe9483589cc98220d62e7ea","41b3dba8542f48638911ed6ab7b4b5f9","a69fe45825a846458690ff1855b4699c","14d044912f134021b86bdef7860c7f04","2882577741774f3696ad6558b65e0fb1","ee21745729fc409f8e27a243aec9a7f5","ca88dce2fcb34cd5b33ba6b11b40a24d","d4ce6ad6f97c43a084d61f8d117c5a5f","3da34d5bcfce4fcc9547b2cc01a891a0","344813fc2c324424a2b45cfe4c335fb5","8bc91cde9504450dbe754cb98f9d0a12","10252d8eafcb482a9c6abcdf7f199a66","89aa45b8c5fb48d0ae85df8c3b5b9964","2120584250e7424ca42d036de4202721","6ae843a316cc429f924c734320207eba","ec2d2112da544c7fac62010ee18a5998","6af17c2e6aa741d397c21d29432ea01e","604c8a8b95144d088c46e595654b8d35"]},"id":"pS2br1iJm-xg","executionInfo":{"status":"ok","timestamp":1630943620671,"user_tz":-180,"elapsed":18926,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"1369943c-cb11-44ae-9618-a0e8f59499eb"},"source":["HeBERT = 'avichr/heBERT'\n","hebert = AutoModel.from_pretrained(HeBERT, force_download=True)\n","tokenizer = BertTokenizer.from_pretrained(HeBERT, do_lower_case=True)\n","## add the 'SEP' and 'CLS' tokens, will later be used in modifiying the texts to the summarzaion model\n","sep_vid = tokenizer.vocab[\"[SEP]\"]\n","cls_vid = tokenizer.vocab[\"[CLS]\"]"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7a7740e31ad4020af10aa43b072a7e3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/505 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8a718be92bd4978a0b313b53edfc1dc","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at avichr/heBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at avichr/heBERT and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4ce6ad6f97c43a084d61f8d117c5a5f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/299k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"tmxeZIXQyBdL","executionInfo":{"status":"ok","timestamp":1630943620675,"user_tz":-180,"elapsed":28,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["MAX_POS = 1024"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GLcBkGnz3AZ7"},"source":["## Preprocess methods"]},{"cell_type":"code","metadata":{"id":"gQuKnMpdSJnI","executionInfo":{"status":"ok","timestamp":1630943620675,"user_tz":-180,"elapsed":25,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["def preprocess(source, max_pos=MAX_POS):\n","    \"\"\"\n","    a simple preprocess function\n","    - Remove \\n\n","    - Sentence Tokenize\n","    - Add [SEP] [CLS] as sentence boundary\n","    \"\"\"\n","    source = source[:max_pos]\n","    raw_text = str(source).replace(\"\\n\", \" \")\n","    sents = sent_tokenize(raw_text)\n","    processed_text = \"[CLS] [SEP]\".join(sents)\n","    return processed_text\n","\n","def preprocess_with_label(source, label, max_pos=MAX_POS):\n","    \"\"\"\n","    preprocess with a twist - insert gold standatrd summaraztion text into the source\n","    - Remove \\n\n","    - Sentence Tokenize\n","    - Add [SEP] [CLS] as sentence boundary\n","    \"\"\"\n","    raw_text = str(source).replace(\"\\n\", \" \")\n","    sents = sent_tokenize(raw_text[:min(max_pos-len(label), len(source))])\n","    idx = 0\n","    if len(sents) > 0:\n","      idx = random.choice(range(len(sents)))\n","      sents = sents[:idx] + [label + '.'] + sents[idx:]\n","      processed_text = \"[CLS] [SEP]\".join(sents)\n","      vec = [0] * len(sents)\n","      vec[idx] = 1\n","      assert(len(vec) == len(sents))\n","    else:\n","        processed_text, vec = \"\", []\n","    return processed_text, torch.Tensor(vec).to(device)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_XXadXkuEvP","executionInfo":{"status":"ok","timestamp":1630943620675,"user_tz":-180,"elapsed":24,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["  def load_text(processed_text, max_pos, device):\n","\n","    def _process_src(raw):\n","        raw = raw.strip().lower()\n","        raw = raw.replace(\"[cls]\", \"[CLS]\").replace(\"[sep]\", \"[SEP]\")\n","        src_subtokens = tokenizer.tokenize(raw)\n","        src_subtokens = [\"[CLS]\"] + src_subtokens + [\"[SEP]\"]\n","        src_subtoken_idxs = tokenizer.convert_tokens_to_ids(src_subtokens)\n","        src_subtoken_idxs = src_subtoken_idxs[:-1][:max_pos]\n","        src_subtoken_idxs[-1] = sep_vid\n","        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == sep_vid]\n","        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n","        \n","        segments_ids = []\n","        segs = segs[:max_pos]\n","        for i, s in enumerate(segs):\n","            if i % 2 == 0:\n","                segments_ids += s * [0]\n","            else:\n","                segments_ids += s * [1]\n","\n","        src = torch.tensor(src_subtoken_idxs)[None, :].to(device)\n","        mask_src = (1 - (src == 0).int()).to(device)\n","        cls_ids = [[i for i, t in enumerate(src_subtoken_idxs) if t == cls_vid]]\n","        clss = torch.tensor(cls_ids).to(device)\n","        mask_cls = (1 -(clss == -1).int()).to(device)\n","        clss[clss == -1] = 0\n","        return src, mask_src, torch.Tensor(segments_ids).to(device), clss, mask_cls.to(device)\n","\n","    src, mask_src, segments_ids, clss, mask_cls = _process_src(processed_text)\n","    segs = torch.tensor(segments_ids)[None, :].to(device)\n","    src_text = [[sent.replace(\"[SEP]\", \"\").strip() for sent in processed_text.split(\"[CLS]\")]]\n","    return src, mask_src, segs, clss, mask_cls, src_text"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03i88mChs-3w"},"source":["## Test Preprocess on a a text"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I2DEnnr4tD--","executionInfo":{"status":"ok","timestamp":1630943630251,"user_tz":-180,"elapsed":9599,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"e89f4cfe-3b19-4a66-a77b-66e14eafcfc7"},"source":["processed_text_sample = preprocess(sample['articleBody'].values[0])\n","data_sample = load_text(processed_text_sample, MAX_POS, device=device)\n","print(data_sample)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[    2, 17478,  7540,  6762,  3966, 14814,  5066,  2393,  1517, 13720,\n","          2870,    12,  5710,    13,    18,     2,     3,  2376,  3187,  3319,\n","          6175,  7439,  1764,  4209,  6514,  7572,  1868,  2308,  1592,  2671,\n","         12237, 15724,  3104,    16,  3666,  2117,  2130,    17,  3214,    16,\n","         17924,    16,  3312,  4578, 21431,  1511, 10988,    18,     2,     3,\n","         26672, 20270,  1532,  2398,  3668,  9128,  2822,  1031,  1539, 20397,\n","         15724, 12237,  5234,    16,  5137, 19968,  1532, 10723,  1057,  1794,\n","          3980,  3879,    18,     2,     3, 14064, 25683,  5008,  2870, 26472,\n","          1896,  1517,  1778,  5093,  1046,   198,    17,  4437,    30,  3164,\n","          1567,  3988,    30,  3164,  5954,    16,  2553,  8002,  8079,  6640,\n","          2393,   211,    17,  3906,    30,  3164,  5231,  2705,  3832,  5821,\n","            18,     2,     3,  3873,  1607, 20875,  3509,  8169,    16, 11506,\n","          9123,  1648,  5229, 10628, 19973,  1798,    18,  1995,  5943, 17929,\n","          7873,  9161,  5821, 16229,  8139, 16401,  1636,  2795,  4209,  5662,\n","            18,     2,     3, 21178,  5144,  9062,  6503,  3078, 18236,  2804,\n","          1955,  2017,  5103, 13640, 11164,  9442,  1517, 26672,  3070, 27203,\n","          2796,  6352,  1646,  1848,  1030,  1532,  9592, 10510,  1057,    18,\n","             2,     3,     6,  1723, 14327,  2870,  2598, 17924,     6,    16,\n","          6083, 16629,  8863,  1771,    16,  2044,  3772,    18,     2,     3,\n","             6,  1723,  4451,  1599,  1899,  2088, 28907,  1009,    18,     2,\n","             3,  3509,  1946,  5703,  8474, 10037,  5924,  1012,  5478,    18,\n","             2,     3,  2988,  4575,  2647,  8288,  3190,  2662,    11,  7077,\n","         10231,    11,    16,  2867,  9649,  2647,  8169,    18,     2,     3,\n","          1723,  1774, 13728, 24135,  9940,  4454,  2188,     6,    18,     2,\n","             3, 26261,  9178,  1012,    16,  2044,  3688, 11152,  3378,    16,\n","         11680,  1057, 11688,  4194,  1052, 12260, 23042,  1019,  5595,  2700,\n","          2130,    18,     2,     3,     6,  8609,  1532,  1791,  8493,    16,\n","          1723,  1961,  6604,    16,  1607,  2397,     6,    16,  2243,    18,\n","             2,     3,  1532, 10546,  1873,  1744, 27334, 13415,  1939,     3]],\n","       device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1]], device='cuda:0', dtype=torch.int32), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n","         1., 1.]], device='cuda:0'), tensor([[  0,  15,  48,  73, 111, 141, 170, 188, 199, 210, 228, 239, 262, 280]],\n","       device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0',\n","       dtype=torch.int32), [['מיזם התחבורה הציבורית בשבת בגוש דן החל את פעילותו הערב (שישי).', 'במהלך סוף השבוע יצאו לדרכם לראשונה חמישה קווי אוטובוס שייסעו בערים מרכזיות באזור, בהן תל אביב-יפו, גבעתיים, רמת השרון וקריית אונו.', 'האוטובוסים יעברו על פני מאות תחנות שמוקמו בנקודות מרכזיות בערים השונות, ויחלפו על פניהן בכל חצי שעה.', 'הקווים שהחלו לפעול הערב יסיימו את נסיעתם ב-01:00 או 03:00 בלילה, וישובו לפעילות מחר החל מ-09:00 בבוקר ועד לצאת השבת.', 'בשלב זה יינתן השירות בחינם, ובהמשך ייקבע המחיר וכיצד ייגבה.כבר בשעות המוקדמות שלאחר כניסת השבת נראו נוסעים העושים שימוש לראשונה בשירות.', 'בתחנה ברחוב כצנלסון בגבעתיים נצפו כמה צעירים שהחליטו לנצל את האוטובוסים החדש ולהימנע מהוויכוח על הנהג התורן.', '\"אני נוסע הערב בתוך גבעתיים \", סיפר ניב מסיקה, בן 27.', '\"אני הולך עם חבר שלי לפאב.', 'השירות הזה נשמע נחמד והחלטתי לנסות.', \"הייתי בטוח שזה יעלה כסף במסגרת 'חופשי חודשי', קצת מוזר שזה בחינם.\", 'אני רק מפחד שעכשיו החרדים ימחו\".', 'עמרי קמחי, בן 26 מרמת גן, המתין לקו 705 בדרכו לנחלת בנימין בתל אביב.', '\"שמעתי על כך בפייסבוק, אני מאוד בעד, זה חשוב\", אמר.', 'על התחנה נתלו שלטי מחאה נגד ה']])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning:\n","\n","To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"zU33S8yWrq9L"},"source":["## Check and remove nans in our dataset"]},{"cell_type":"code","metadata":{"id":"bLmSwrNySVcI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630943630252,"user_tz":-180,"elapsed":41,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"cf524a61-48fd-4801-fd76-4dfc8efe1bbc"},"source":["print('Number of nans in description column: ', len(re_df[re_df['description'].isna() == True]))\n","print('Number of nans in articleBody column: ', len(re_df[re_df['articleBody'].isna() == True]))\n","\n","texts = re_df['articleBody']\n","labels = re_df['description']\n","### removing nans, if appliable\n","texts = re_texts.drop(re_texts[re_texts.isna()==True].index, axis=0)\n","labels = re_labels.drop(re_labels[re_labels.isna()==True].index, axis=0)\n","assert(len(texts) == len(labels))\n","print('Total samples :', len(texts))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of nans in description column:  0\n","Number of nans in articleBody column:  0\n","Total samples : 584\n"]}]},{"cell_type":"markdown","metadata":{"id":"axmCb9Smx7gv"},"source":["## PreProcess Data - using preprocess with label"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWzN-3y8EePe","executionInfo":{"status":"ok","timestamp":1630943634145,"user_tz":-180,"elapsed":3912,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"4fb52125-f596-49c7-fa2e-b1bfdd2d8fd6"},"source":["pairs_orig = [(load_text(preprocess(text), max_pos=MAX_POS, device=device), label) for text, label in zip(re_texts, re_labels) if len(text) > 5]\n","processed_texts = [pair[0] for pair in pairs_orig]\n","labels_text = [pair[1] for pair in pairs_orig]"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning:\n","\n","To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGvJkr5-vw0o","executionInfo":{"status":"ok","timestamp":1630943638933,"user_tz":-180,"elapsed":4811,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"5bc07bc7-41a0-4f0c-c390-77807e8e8163"},"source":["pairs_orig_j = [(load_text(preprocess(text), max_pos=MAX_POS, device=device), load_text(preprocess(label), max_pos=MAX_POS, device=device)) for text, label in zip(re_texts, re_labels) if len(text) > 5]\n","processed_texts_j = [pair[0] for pair in pairs_orig_j]\n","processed_labels_j = [pair[1] for pair in pairs_orig_j]"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning:\n","\n","To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","\n"]}]},{"cell_type":"code","metadata":{"id":"y0itIM1Mx63V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630943642717,"user_tz":-180,"elapsed":3797,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"b014bceb-92ed-4b32-c252-b8c87620137c"},"source":["pairs = [preprocess_with_label(text, label) for text, label in zip(re_texts, re_labels)]\n","labels_vec = [pair[1] for pair in pairs if len(pair[0]) > 5]\n","processed_texts_with_label = [load_text(pair[0], max_pos=MAX_POS, device=device) for pair in pairs if len(pair[0]) > 5]\n","assert(len(labels_vec) == len(processed_texts_with_label))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning:\n","\n","To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"BbmedCqKluAg"},"source":["# HeBERT Summarizer"]},{"cell_type":"markdown","metadata":{"id":"XRk1RoNU4b-0"},"source":["## HeBert Summarizer obj and functions"]},{"cell_type":"code","metadata":{"id":"E_UFLjednGFE","executionInfo":{"status":"ok","timestamp":1630943643059,"user_tz":-180,"elapsed":349,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["class summarizer(nn.Module):\n","  def __init__(self, bert_model):\n","    super().__init__()\n","    self.bert = bert_model\n","    self.ext_layer = ExtTransformerEncoder(self.bert.config.hidden_size, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2)\n","\n","  def forward(self, src, segs, clss, mask_src, mask_cls):\n","    top_vec = self.bert(src, segs, mask_src).last_hidden_state\n","    sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n","    sents_vec = sents_vec * mask_cls[:, :, None].float()\n","    sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n","    return sent_scores, mask_cls\n","  \n","\n","def train(model, optimizer, input_data, labels, epochs=5):\n","  criterion = torch.nn.BCELoss(reduction='sum')\n","  model.train()\n","  for epoch in range(epochs):\n","    loss = 0\n","    for i, data in enumerate(input_data):\n","        try:\n","          optimizer.zero_grad()\n","          src, mask, segs, clss, mask_cls, _ = data\n","          sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","          cur_loss = criterion(sent_scores , labels[i].view(1,-1))\n","          cur_loss.backward()\n","          optimizer.step()\n","          loss += cur_loss.item()\n","        except Exception as e:\n","          # print(e)\n","          continue\n","\n","    print(\"epoch:\", epoch, \"\\t loss:\", loss/len(input_data))\n","  return loss\n","\n","def predict(model, input_data, max_length, block_trigram=True):\n","    def _get_ngrams(n, text):\n","        ngram_set = set()\n","        text_length = len(text)\n","        max_index_ngram_start = text_length - n\n","        for i in range(max_index_ngram_start + 1):\n","            ngram_set.add(tuple(text[i : i + n]))\n","        return ngram_set\n","\n","    def _block_tri(c, p):\n","        tri_c = _get_ngrams(3, c.split())\n","        for s in p:\n","            tri_s = _get_ngrams(3, s.split())\n","            if len(tri_c.intersection(tri_s)) > 0:\n","                return True\n","        return False\n","\n","    with torch.no_grad():\n","        src, mask, segs, clss, mask_cls, src_str = input_data\n","        sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","        sent_scores = sent_scores + mask.float()\n","        sent_scores = sent_scores.cpu().data.numpy()\n","        selected_ids = np.argsort(-sent_scores, 1)\n","\n","        pred = []\n","        for i, idx in enumerate(selected_ids):\n","            _pred = []\n","            if len(src_str[i]) == 0:\n","                continue\n","            for j in selected_ids[i][: len(src_str[i])]:\n","                if j >= len(src_str[i]):\n","                    continue\n","                candidate = src_str[i][j].strip()\n","                if block_trigram:\n","                    if not _block_tri(candidate, _pred):\n","                        _pred.append(candidate)\n","                else:\n","                    _pred.append(candidate)\n","\n","                if len(_pred) == max_length:\n","                    break\n","\n","            _pred = \" \".join(_pred)\n","            pred.append(_pred)\n","    ret = ''\n","    for i in range(len(pred)):\n","      ret += pred[i].strip() + \"\\n\"\n","    return ret\n","\n","def get_num_segs(seg):\n","  c = 1\n","  cur = 0\n","  for i in seg:\n","    if i != cur:\n","      c += 1\n","      cur = i\n","  return c\n","\n","def get_label_by_rouge(sentences, title, num_segs):\n","  rouge_scorer = Rouge()\n","  scores = []\n","  for sentence in sentences:\n","    if len(scores) == num_segs: # in case text exceeded max_pos\n","      break\n","    try:\n","      scores.append(rouge_scorer.get_scores(sentence, title)[0]['rouge-l']['f']) # use f1 score of ROUGE-L\n","    except Exception as e:\n","      scores.append(0.0) # sentence is \".\" or something similar\n","  \n","  label = [0] * len(scores)\n","  label[np.argmax(scores)] = 1\n","  return torch.FloatTensor(label).to(device)\n","\n","def get_label_for_sentence_by_jaccard(sentences, desc):\n","  mask = sentences[2].view(-1)\n","  tokens = sentences[0].view(-1)\n","  scores = []\n","  last_change = 0\n","  for i in range(len(mask)-1):\n","    if mask[i] != mask[i+1]:\n","      scores.append(len(np.intersect1d(tokens[last_change:i+1].cpu().numpy(), desc.cpu().numpy())))\n","      last_change = i+1\n","  \n","  scores.append(len(np.intersect1d(tokens[last_change:].cpu().numpy(), desc.cpu().numpy())))\n","  label = [0] * len(scores)\n","  label[np.argmax(scores)] = 1\n","\n","  return torch.FloatTensor(label).to(device)\n","\n","def eval(model, data, labels):\n","  rouge_scorer = Rouge()\n","  right = 0\n","  non_accurate = 0\n","  score = 0\n","  with torch.no_grad():\n","    for i, text in enumerate(data):\n","      try:\n","        src, mask, segs, clss, mask_cls, orig_text = text\n","        sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","        pred = torch.argmax(sent_scores).item()\n","        label = torch.argmax(labels[i]).item()\n","        if pred == label:\n","          right += 1\n","        else:\n","          non_accurate += 1\n","        score += rouge_scorer.get_scores(orig_text[0][pred], orig_text[0][label])[0]['rouge-l']['f']\n","      except:\n","        continue\n","  return right, non_accurate, score/(right+non_accurate)\n","\n","def print_eval_results(model, data, labels):\n","  right , non_accurate, f1rouge = eval(model, data, labels)\n","  print(\"Total accuracy: {}, F1-Rouge-L score {}\".format(right/ (right + non_accurate), f1rouge))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXA6FXIjs19k","executionInfo":{"status":"ok","timestamp":1630943643059,"user_tz":-180,"elapsed":4,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}}},"source":["def load_saved_hebert_model(path, train=True):\n","  model = summarizer(hebert)\n","  optimizer = Adam(model.parameters(), lr=0.001, eps=1e-9)\n","  checkpoint = torch.load(path)\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","  epoch = checkpoint['epoch']\n","  loss = checkpoint['loss']\n","\n","  if train:\n","    model.train()\n","  else:\n","    model.eval()\n","\n","  return model, optimizer"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rGx2M4V74lh7"},"source":["# Experiments"]},{"cell_type":"markdown","metadata":{"id":"Zyqge_hv5Vxw"},"source":["We present 4 Experiments over our dataset, in an attempt to achieve the best summarization."]},{"cell_type":"markdown","metadata":{"id":"GnIwggH_6G4g"},"source":["## Experiment #0 - BaseLine\n","Testing the HeBERT ability to summarize text following the BERTSUM architecture changes without any fine-tuning on our dataset.<br>\n","The label for each article, which is the sentence that best summarizes the text, will be the sentence from within the body of the article that is closest to the description of the article using ROUGE-L F1 score.\n"]},{"cell_type":"code","metadata":{"id":"rSODxrWa6dB-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630943688177,"user_tz":-180,"elapsed":45121,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"8fe6563f-9ab0-47c3-9f2a-4b8620641795"},"source":["hebert_sum = summarizer(hebert)\n","hebert_sum = hebert_sum.to(device)\n","rouge_labels_all = [get_label_by_rouge(processed_texts[i][-1][0], labels_text[i], get_num_segs(processed_texts[i][2][0])) for i in range(len(processed_texts))]\n","print_eval_results(hebert_sum, processed_texts, rouge_labels_all)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/bert-extractive-summarization/models/neural.py:168: UserWarning:\n","\n","masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","\n"]},{"output_type":"stream","name":"stdout","text":["Total accuracy: 0.11492281303602059, F1-Rouge-L score 0.15921295228656862\n"]}]},{"cell_type":"markdown","metadata":{"id":"htkgAVgi1Ia0"},"source":["## Experiment #1\n","\n","The label for training is the same as the label for test.<br>\n","The label for each article, which is the sentence that best summarizes the text, will be the sentence from within the body of the article that is closest to the description of the article using ROUGE-L F1 score.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UElnRQtlCgKr","executionInfo":{"status":"ok","timestamp":1630945961023,"user_tz":-180,"elapsed":2272873,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"47fe90a5-4152-4a5b-c0cc-2b618fc0d5b1"},"source":["hebert_sum_rouge = summarizer(hebert)\n","hebert_sum_rouge = hebert_sum_rouge.to(device)\n","X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(processed_texts, labels_text, range(len(labels_text)), test_size=0.1, random_state=10)\n","optimizer = Adam(hebert_sum_rouge.parameters(), lr=0.001, eps=1e-9, betas=[0.9, 0.999])\n","rouge_labels_train = [get_label_by_rouge(X_train[i][-1][0], y_train[i], get_num_segs(X_train[i][2][0])) for i in range(len(X_train))]\n","epochs = 20\n","final_loss = train(hebert_sum_rouge, optimizer, X_train, rouge_labels_train, epochs=epochs)\n","# torch.save({\n","#             'epoch': epochs,\n","#             'model_state_dict': hebert_sum_rouge.state_dict(),\n","#             'optimizer_state_dict': optimizer.state_dict(),\n","#             'loss': final_loss/len(X_train)\n","#             },f\"/content/drive/MyDrive/Masters First Year/NLP/Final Proj/rouge_model_{epochs}.tar\")\n","\n","print('Train eval results:')\n","print_eval_results(hebert_sum_rouge, X_train, rouge_labels_train)\n","\n","print('Test eval results:')\n","rouge_labels_test = [get_label_by_rouge(X_test[i][-1][0], y_test[i], get_num_segs(X_test[i][2][0])) for i in range(len(X_test))]\n","print_eval_results(hebert_sum_rouge, X_test, rouge_labels_test)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/bert-extractive-summarization/models/neural.py:168: UserWarning:\n","\n","masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0 \t loss: 3.4168450595768354\n","epoch: 1 \t loss: 3.1474122282202917\n","epoch: 2 \t loss: 3.163495206650887\n","epoch: 3 \t loss: 3.1464247817301567\n","epoch: 4 \t loss: 3.13647196493076\n","epoch: 5 \t loss: 3.1456618090622297\n","epoch: 6 \t loss: 3.1540625286466293\n","epoch: 7 \t loss: 3.164990616663722\n","epoch: 8 \t loss: 3.1621402752308447\n","epoch: 9 \t loss: 3.1437080557109747\n","epoch: 10 \t loss: 3.1614237031863848\n","epoch: 11 \t loss: 3.133929811361182\n","epoch: 12 \t loss: 3.137342304218816\n","epoch: 13 \t loss: 3.146078703057675\n","epoch: 14 \t loss: 3.1406930753292928\n","epoch: 15 \t loss: 3.1375304738073857\n","epoch: 16 \t loss: 3.122884641166862\n","epoch: 17 \t loss: 3.113286261340134\n","epoch: 18 \t loss: 3.118809333511891\n","epoch: 19 \t loss: 3.1263116229581467\n","Train eval results:\n","Total accuracy: 0.14694656488549618, F1-Rouge-L score 0.1954740814258561\n","Test eval results:\n","Total accuracy: 0.0847457627118644, F1-Rouge-L score 0.1390711691019701\n"]}]},{"cell_type":"markdown","metadata":{"id":"lYYJrMxR4tdL"},"source":["## Experiment #2\n","\n","Inserting the description into the article body's text while training, then using the location of the description as the label. <br>\n","Test label is as in the previous experiment.\n"]},{"cell_type":"code","metadata":{"id":"zd4OC3tLF4cu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630948283221,"user_tz":-180,"elapsed":2322225,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"4fb971e2-7629-4185-9976-3a9baddd862e"},"source":["hebert_sum_desc_in = summarizer(hebert)\n","hebert_sum_desc_in = hebert_sum_desc_in.to(device)\n","X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(processed_texts_with_label, labels_vec, range(len(labels_vec)), test_size=0.1, random_state=10)\n","optimizer = Adam(hebert_sum_desc_in.parameters(), lr=0.001, eps=1e-9, betas=[0.9, 0.999])\n","epochs = 20\n","final_loss = train(hebert_sum_desc_in, optimizer, X_train, y_train, epochs=epochs)\n","# torch.save({\n","#             'epoch': epochs,\n","#             'model_state_dict': hebert_sum_desc_in.state_dict(),\n","#             'optimizer_state_dict': optimizer.state_dict(),\n","#             'loss': final_loss/len(X_train)\n","#             }, f\"/content/drive/MyDrive/Masters First Year/NLP/Final Proj/rouge_model_with_label_insert_{epochs}.tar\")\n","\n","print('Train eval results:')\n","print_eval_results(hebert_sum_desc_in, X_train, y_train)\n","test_texts_label = re_df.iloc[idx_test]\n","X_test = np.array(processed_texts)[idx_test]\n","rouge_labels = [get_label_by_rouge(X_test[i][-1][0], test_texts_label.iloc[i], get_num_segs(X_test[i][2][0])) for i in range(len(X_test))]\n","print('Test eval results:')\n","print_eval_results(hebert_sum_desc_in, X_test, rouge_labels)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/bert-extractive-summarization/models/neural.py:168: UserWarning:\n","\n","masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0 \t loss: 3.2561467467373566\n","epoch: 1 \t loss: 3.151883061150558\n","epoch: 2 \t loss: 3.1402907580819748\n","epoch: 3 \t loss: 3.128541143340919\n","epoch: 4 \t loss: 3.152829005745531\n","epoch: 5 \t loss: 3.1412915598800164\n","epoch: 6 \t loss: 3.1263063581845234\n","epoch: 7 \t loss: 3.1197508983029665\n","epoch: 8 \t loss: 3.121711722084584\n","epoch: 9 \t loss: 3.119796545450924\n","epoch: 10 \t loss: 3.106259200864166\n","epoch: 11 \t loss: 3.0992170481281427\n","epoch: 12 \t loss: 3.1071566848354486\n","epoch: 13 \t loss: 3.1218973916905526\n","epoch: 14 \t loss: 3.1084269214677445\n","epoch: 15 \t loss: 3.117094032864534\n","epoch: 16 \t loss: 3.1049534967382444\n","epoch: 17 \t loss: 3.0968286256298763\n","epoch: 18 \t loss: 3.0966840622989276\n","epoch: 19 \t loss: 3.1468508266310655\n","Train eval results:\n","Total accuracy: 0.14885496183206107, F1-Rouge-L score 0.22735528639975316\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning:\n","\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","\n"]},{"output_type":"stream","name":"stdout","text":["Test eval results:\n","Total accuracy: 0.1864406779661017, F1-Rouge-L score 0.23259662468147052\n"]}]},{"cell_type":"markdown","metadata":{"id":"LeyKHgyku2w2"},"source":["<br>\n","The label for each article, which is the sentence that best summarizes the text, will be the sentence from within the body of the article that is closest to the description of the article using Jaccard similarity score."]},{"cell_type":"code","metadata":{"id":"v5mkpoRDw_rC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630950555125,"user_tz":-180,"elapsed":2271909,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"043d3779-1479-46a3-c75e-5cc4a39e8f71"},"source":["hebert_sum_jaccard = summarizer(hebert)\n","hebert_sum_jaccard = hebert_sum_jaccard.to(device)\n","X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(processed_texts_j, processed_labels_j, range(len(processed_labels_j)), test_size=0.1, random_state= 10)\n","optimizer = Adam(hebert_sum_jaccard.parameters(), lr=0.001, eps=1e-9, betas=[0.9, 0.999])\n","jaccard_labels_train = [get_label_for_sentence_by_jaccard(X_train[i], y_train[i][0]) for i in range(len(y_train))]\n","epochs = 20\n","final_loss = train(hebert_sum_jaccard, optimizer, X_train, jaccard_labels_train, epochs=epochs)\n","# torch.save({\n","#             'epoch': epochs,\n","#             'model_state_dict': hebert_sum_jaccard.state_dict(),\n","#             'optimizer_state_dict': optimizer.state_dict(),\n","#             'loss': final_loss/len(X_train)\n","#             },f\"/content/drive/MyDrive/Masters First Year/NLP/Final Proj/jaccard_model_{epochs}.tar\")\n","\n","print('Train eval results:')\n","print_eval_results(hebert_sum_jaccard , X_train, jaccard_labels_train)\n","\n","print('Test eval results to jaccard labels:')\n","jaccard_labels_test = [get_label_for_sentence_by_jaccard(X_test[i], y_test[i][0]) for i in range(len(X_test))]\n","print_eval_results(hebert_sum_jaccard, X_test, jaccard_labels_test)\n","\n","rouge_labels = [get_label_by_rouge(X_test[i][-1][0], y_test[i], get_num_segs(X_test[i][2][0])) for i in range(len(X_test))]\n","print('Test eval results to rouge labels:')\n","print_eval_results(hebert_sum_jaccard, X_test, rouge_labels)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/bert-extractive-summarization/models/neural.py:168: UserWarning:\n","\n","masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0 \t loss: 3.234019856416542\n","epoch: 1 \t loss: 3.1352593239027127\n","epoch: 2 \t loss: 3.1588123822940215\n","epoch: 3 \t loss: 3.1469533675499544\n","epoch: 4 \t loss: 3.1238897169819313\n","epoch: 5 \t loss: 3.1157209477351824\n","epoch: 6 \t loss: 3.104453434243457\n","epoch: 7 \t loss: 3.142199685555378\n","epoch: 8 \t loss: 3.1298101093932873\n","epoch: 9 \t loss: 3.146158279808423\n","epoch: 10 \t loss: 3.135597749975801\n","epoch: 11 \t loss: 3.11209923188195\n","epoch: 12 \t loss: 3.1449480682383966\n","epoch: 13 \t loss: 3.105233308468156\n","epoch: 14 \t loss: 3.1291236258645094\n","epoch: 15 \t loss: 3.1259208990417364\n","epoch: 16 \t loss: 3.144496167434081\n","epoch: 17 \t loss: 3.152257397884631\n","epoch: 18 \t loss: 3.1363814391252647\n","epoch: 19 \t loss: 3.1192359410169472\n","Train eval results:\n","Total accuracy: 0.13358778625954199, F1-Rouge-L score 0.17879564972524917\n","Test eval results to jaccard labels:\n","Total accuracy: 0.1864406779661017, F1-Rouge-L score 0.2366187314767476\n","Test eval results to rouge labels:\n","Total accuracy: 0.15254237288135594, F1-Rouge-L score 0.18636269795022983\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0i4rUT6Qdn6","executionInfo":{"status":"ok","timestamp":1630950555125,"user_tz":-180,"elapsed":49,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"c8cbb06b-d29c-4ca7-dbe5-a9c244fa1b4f"},"source":["print(\"orig text:\\n\", \"\\n\".join(processed_texts[0][-1][0]))\n","label_by_rouge = get_label_by_rouge(processed_texts[0][-1][0], labels_text[0], get_num_segs(processed_texts[0][2][0]))\n","print(\"label by rouge to description:\\n\", processed_texts[0][-1][0][torch.argmax(label_by_rouge).item()])\n","print(\"orig label:\\n\", labels_text[0])\n","rouge_scorer = Rouge()\n","rouge_scorer.get_scores(labels_text[0], processed_texts[0][-1][0][torch.argmax(label_by_rouge).item()])[0]['rouge-l']['f']"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["orig text:\n"," זוכי תוכנית מחיר למשתכן ברחוב דבורה עומר ברעננה גילו לאחרונה כי בפרויקט שלהם תוצמד רק חניה אחת לדירה, בעוד יתר החניות יישארו בידי הקבלן, שלטענתם מעוניין למכור אותן בשוק החופשי.\n","הפרויקט נמצא בהליכי קידום וטרם התקבל לו היתר בנייה.\n","הוא כולל חמישה בניינים בני תשע קומות, ובסך הכל 147 דירות, מהן 27 יימכרו בשוק החופשי והיתר במסגרת מחיר למשתכן.\n","בנוסף לכך הפרויקט כולל שטחי מסחר.\n","המחיר לזכאים עומד על כ־14 אלף שקל למ”ר, וטווח המחירים נע בין כ־1.2 מיליון שקל ל־2 מיליון שקל לדירת מחיר למשתכן.\n","לפי התב\"ע, לפרויקט יש 298 חניות תת־קרקעיות.\n","לכל אחת מהדירות שיימכרו בשוק החופשי יוצמדו שתי חניות, ובסך הכל 54 חניות, בעוד ליתר 120 הדירות תוצמד רק חניה אחת.\n","כ־20 חניות יוצמדו לשטחי המסחר.\n","מכל זאת יוצא ש־104 חניות נותרות ללא הצמדה.\n","לטענת הרוכשים, הקבלן כמיל שגראווי מחברת שגראווי SBC אמר להם כי בכוונתו למכור את החניות בשוק החופשי, אף שהמפרט של תוכנית מחיר למשתכן אוסר על כך.\n","לפי המפרט, שהופץ על ידי משרד השיכון בדצמבר 2017, \"כל החניות המתוכננות בתחום המגרשים יוצמדו לדירות המתוכננות במגרשים.\n","למען הסר ספק, לא ניתן יהיה להו\n","label by rouge to description:\n"," לטענת הרוכשים, הקבלן כמיל שגראווי מחברת שגראווי SBC אמר להם כי בכוונתו למכור את החניות בשוק החופשי, אף שהמפרט של תוכנית מחיר למשתכן אוסר על כך.\n","orig label:\n"," קבלן ברעננה תכנן לפרויקט 298 חניות, ששליש מהן הוא מתכוון למכור בשוק החופשי. המפרט של משרד הבינוי אוסר זאת, אך העירייה מתירה לו\n"]},{"output_type":"execute_result","data":{"text/plain":["0.16666666167534736"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"lHxieULkWNTp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630950555126,"user_tz":-180,"elapsed":22,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"993603ba-8beb-48f7-c42e-8f185ec8ea80"},"source":["print(predict(hebert_sum, processed_texts[0], 1, True))\n","print(labels_text[0])"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["בנוסף לכך הפרויקט כולל שטחי מסחר.\n","\n","קבלן ברעננה תכנן לפרויקט 298 חניות, ששליש מהן הוא מתכוון למכור בשוק החופשי. המפרט של משרד הבינוי אוסר זאת, אך העירייה מתירה לו\n"]},{"output_type":"stream","name":"stderr","text":["/content/bert-extractive-summarization/models/neural.py:168: UserWarning:\n","\n","masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"Cnd0i3eiBCNo","executionInfo":{"status":"ok","timestamp":1630950555127,"user_tz":-180,"elapsed":14,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"d08008aa-1408-4780-9941-2cea22469ef9"},"source":["src, mask, segs, clss, mask_cls, orig_text = processed_texts[0]\n","sent_scores, mask = hebert_sum_desc_in(src, segs, clss, mask, mask_cls)\n","pred = torch.argmax(sent_scores).item()\n","orig_text[0][pred]"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/bert-extractive-summarization/models/neural.py:168: UserWarning:\n","\n","masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'המחיר לזכאים עומד על כ־14 אלף שקל למ”ר, וטווח המחירים נע בין כ־1.2 מיליון שקל ל־2 מיליון שקל לדירת מחיר למשתכן.'"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIowE8AZz0g5","executionInfo":{"status":"ok","timestamp":1630950555543,"user_tz":-180,"elapsed":424,"user":{"displayName":"Rotem Shalev","photoUrl":"","userId":"04644005104476595022"}},"outputId":"cc171539-20d9-4427-be15-5c1003476411"},"source":["sent_scores, mask"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.1412, 0.1117, 0.1366, 0.1347, 0.2303, 0.1197, 0.1379, 0.1801, 0.1946,\n","          0.2067, 0.2278, 0.1273]], device='cuda:0', grad_fn=<SqueezeBackward1>),\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0',\n","        dtype=torch.int32))"]},"metadata":{},"execution_count":27}]}]}